{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the file `movie_titles_canonical.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_mtc = sc.textFile(\"movie_titles_canonical.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_nmt = sc.textFile(\"netflix_movie_titles.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the file contents to lower case and split using comma. The movie title is then manipulated using the regex functions to all special characters including space is removed, while some common words are also removed. The year is added as a concatenation to the title of the movie as this created a better unique identifier for the movie. \n",
    "\n",
    "All the original data is kept as the value so that we can reference to it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_mtc = (raw_mtc\n",
    "              .map(lambda x: x.split(\",\"))\n",
    "              .map(lambda x: (re.sub('\\W+','',\n",
    "                                     re.sub('the |of |is |a ', '', x[0].lower())) + x[1], [x[0], x[1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_nmt = (raw_nmt\n",
    "              .map(lambda x: x.split(\",\"))\n",
    "              .map(lambda x: (re.sub('\\W+','', \n",
    "                                     re.sub('the |of |is |a ', '', x[2].lower())) + x[1], [x[0], x[1], x[2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a representation of the transformed RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('avatar2009', ['Avatar', '2009']),\n",
       " ('amélie2001', ['Amélie', '2001']),\n",
       " ('fullmetaljacket1987', ['Full Metal Jacket', '1987']),\n",
       " ('etextraterrestrial1982', ['E.T.: The Extra-Terrestrial', '1982']),\n",
       " ('independenceday1996', ['Independence Day', '1996'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mtc.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dinosaurplanet2003', ['1', '2003', 'Dinosaur Planet']),\n",
       " ('islemantt2004review2004', ['2', '2004', 'Isle of Man TT 2004 Review']),\n",
       " ('character1997', ['3', '1997', 'Character']),\n",
       " ('paulabdulsgetupdance1994', ['4', '1994', \"Paula Abdul's Get Up & Dance\"]),\n",
       " ('riseandfallecw2004', ['5', '2004', 'The Rise and Fall of ECW'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nmt.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two RDDs can be joined on the key that should be unique and is close to to the second file, so that more movies can be matched. Infact the reason the two files where manipulated in the same way so that the final key is unique and can be joined as it would be the same in both files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_joined_mtc_nmt = data_mtc.join(data_nmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3728"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_joined_mtc_nmt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final joined RDD is then mapped to get the final desired output which is `ID => TITLE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_final_mtc_nmt = data_joined_mtc_nmt.map(lambda x: (int(x[1][1][0]), x[1][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the RDD is transformed to a dictionary and broadcasted to all spark clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic_final_mtc_nmt = data_final_mtc_nmt.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "broadcast_mov = sc.broadcast(dic_final_mtc_nmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_mas = sc.textFile(\"mv_all_simple.txt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_mas_1, raw_mas_2 = raw_mas.randomSplit(weights=[0.8, 0.2], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings_mas = (raw_mas_1.map(lambda x: x.split(','))\n",
    "    .map(lambda l: Rating(int(l[1]), int(l[0]), int(l[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank = 10\n",
    "numIterations = 5\n",
    "regularization_parameter = 0.01\n",
    "model = ALS.train(ratings_mas, rank, numIterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata = ratings_mas.map(lambda p: (p[0], p[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_preds = predictions.filter(lambda x: x[0][0] == 30878)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_recommendations = user_preds.map(lambda x: (x[0][1], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_recommendations_movie_titles = user_recommendations.join(data_final_mtc_nmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_top_recommendations_movie_titles = user_recommendations_movie_titles.map(lambda x: (x[0], x[1][1], x[1][0])).takeOrdered(10, key=lambda x: -x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies:\n",
      "(5582, 'Star Wars: Episode V: The Empire Strikes Back', 4.316707005074456)\n",
      "(14240, 'The Lord of the Rings: The Return of the King', 4.309599588582811)\n",
      "(16265, 'Star Wars: Episode IV - A New Hope', 4.286788548463047)\n",
      "(9628, 'Star Wars: Episode VI - Return of the Jedi', 4.253354490312434)\n",
      "(14050, 'Willy Wonka & the Chocolate Factory', 4.249344217912746)\n",
      "(2452, 'The Lord of the Rings: The Fellowship of the Ring', 4.2296427897135676)\n",
      "(13673, 'Toy Story', 4.2227653792831745)\n",
      "(12870, \"Schindler's List\", 4.211485619896104)\n",
      "(12676, 'The Secret of NIMH', 4.201740547651723)\n",
      "(7193, 'The Princess Bride', 4.199720069522107)\n"
     ]
    }
   ],
   "source": [
    "print ('TOP recommended movies:\\n%s' %\n",
    "        '\\n'.join(map(str, user_top_recommendations_movie_titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_actual = ratings_mas.filter(lambda x: x[0] == 30878)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ratings = user_actual.map(lambda x: (x[1], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ratings_movie_titles = user_ratings.join(data_final_mtc_nmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_ratings_movie_titles = user_ratings_movie_titles.map(lambda x: (x[0], x[1][1], x[1][0])).takeOrdered(10, key=lambda x: -x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP movies:\n",
      "(2212, 'The Secret Garden', 5)\n",
      "(4661, 'Deuce Bigalow: Male Gigolo', 5)\n",
      "(1659, 'Grumpy Old Men', 5)\n",
      "(7745, 'Apollo 13', 5)\n",
      "(6797, 'The Breakfast Club', 5)\n",
      "(2452, 'The Lord of the Rings: The Fellowship of the Ring', 5)\n",
      "(15646, \"Lemony Snicket's A Series of Unfortunate Events\", 5)\n",
      "(2771, 'Top Secret!', 5)\n",
      "(13673, 'Toy Story', 5)\n",
      "(9330, 'For a Few Dollars More', 5)\n"
     ]
    }
   ],
   "source": [
    "print ('TOP movies:\\n%s' %\n",
    "        '\\n'.join(map(str, user_ratings_movie_titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toCSVLine(data):\n",
    "  return ','.join(str(d) for d in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_rec_mov_rdd = sc.parallelize(user_top_recommendations_movie_titles)\n",
    "user_rec_mov_csv = user_rec_mov_rdd.map(toCSVLine)\n",
    "user_rec_mov_csv.saveAsTextFile('user_rec_mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_rat_mov_rdd = sc.parallelize(user_ratings_movie_titles)\n",
    "user_rat_mov_csv = user_rat_mov_rdd.map(toCSVLine)\n",
    "user_rat_mov_csv.saveAsTextFile('user_rat_mov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings_mas_2 = (raw_mas_2.map(lambda x: x.split(','))\n",
    "    .map(lambda l: Rating(int(l[1]), int(l[0]), float(l[2]) - 2.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank = 10\n",
    "numIterations = 10\n",
    "regularization_parameter = 0.01\n",
    "model_2 = ALS.train(ratings_mas_2, rank, numIterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata_2 = ratings_mas_2.map(lambda p: (p.user, p.product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_2  = model_2.predictAll(testdata_2).map(lambda r: ((r.user, r.product), r.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_tuple = ratings_mas_2.map(lambda r: ((r.user, r.product), r.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_labels = predictions_2.join(ratings_tuple).map(lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = RegressionMetrics(score_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.7255143677238088\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE = %s\" % metrics.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_qs = sc.textFile(\"qualifying_simple.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_qs = raw_qs.map(lambda x: x.split(',')).map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1046323', '1'),\n",
       " ('1080030', '1'),\n",
       " ('1830096', '1'),\n",
       " ('368059', '1'),\n",
       " ('802003', '1')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_qs.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_qs_csv = data_qs.map(toCSVLine)\n",
    "data_qs_csv.saveAsTextFile('data_qs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neo4j.v1 import GraphDatabase, basic_auth\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_predictions_1, sample_predictions_2 = predictions_2.randomSplit(weights=[0.05, 0.95], seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_predictions_1 = sample_predictions_1.map(lambda x: (x[0][1], (x[0][0], x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14358, (1393975, 1.342284448695834)),\n",
       " (10921, (1393975, 0.06382050785608284)),\n",
       " (4520, (1393975, 1.0203518089436434)),\n",
       " (7230, (1393975, 2.432663241116531)),\n",
       " (14233, (1393975, 0.9258170484198738))]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predictions_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11863, 'D3: The mighty Ducks'),\n",
       " (482, 'Frida'),\n",
       " (15885, 'Alien Nation'),\n",
       " (17116, 'Stickmen'),\n",
       " (10550, 'Cold Mountain')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final_mtc_nmt.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_predictions = sample_predictions_1.join(data_final_mtc_nmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_predictions = joined_predictions.map(lambda x: (str(x[0]) + str(x[1][0][0]), (x[0], x[1][1], x[1][0][0], x[1][0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4100772745', (4100, 'Dinosaur', 772745, 1.0551761940315265))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_predictions.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_joined_predictions = joined_predictions.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4100, 'Dinosaur', 772745, 1.0551761940315265)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_joined_predictions['4100772745']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=basic_auth(\"neo4j\", \"1234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session = driver.session()\n",
    "  \n",
    "for key in dict_joined_predictions:\n",
    "    raw_data = dict_joined_predictions[key]\n",
    "    \n",
    "    movie_result = session.run('MATCH (m:Movie { id: {movie_id}, title: {movie_title}}) RETURN m', {'movie_id': str(raw_data[0]), 'movie_title' : raw_data[1]})\n",
    "    for movie in movie_result:\n",
    "        user_result = session.run('MERGE (u:User { id: {user_id}}) RETURN u', {'user_id': str(raw_data[2])})\n",
    "        for user in user_result:\n",
    "            user_rated_result = session.run('MATCH (u:User { id: {user_id}}),(m:Movie { id: {movie_id}, title: {movie_title}}) MERGE (u)-[r:RATED{stars:{rating}}]->(m) RETURN r', {'user_id': str(raw_data[2]), 'movie_id': str(raw_data[0]), 'movie_title' : raw_data[1], 'rating' : raw_data[3]})\n",
    "            for user_rating in user_rated_result:\n",
    "                print(\"User: \" + str(user['u']['id']) + \" rated movie \" + movie['m']['id'] + \" \" + movie['m']['title'] + \" \" + user_rated_result['r']['stars'])\n",
    "        \n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709847"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710926"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_joined_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
